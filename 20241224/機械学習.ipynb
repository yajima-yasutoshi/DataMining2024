{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TKlOXVFpJj7q"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajima-yasutoshi/DataMining2024/blob/main/20241224/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 機械学習"
      ],
      "metadata": {
        "id": "DSwFQUGOD0iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 資料の置かれたサイト\n",
        "\n",
        "20241224\n",
        "\n",
        "https://github.com/yajima-yasutoshi/DataMining2024/tree/main/20241224"
      ],
      "metadata": {
        "id": "g8YJ3oojiqNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#講義の目的\n",
        "\n",
        "機械学習による分類手法に関する説明を行う。\n",
        "ここでは、代表的な手法である\n",
        "**決定木**および**ランダムフォレスト**\n",
        "と呼ばれる2つの分類モデルの構築法を理解する。\n"
      ],
      "metadata": {
        "id": "wUezl4MyB_v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 準備\n"
      ],
      "metadata": {
        "id": "8zFBC9q961jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリーのインポート"
      ],
      "metadata": {
        "id": "ZcX_E1F-64Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 日本語環境のインストール\n",
        "!pip install japanize-matplotlib\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# 決定木に必要なライブラリー\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# その他必要なライブラリー\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "g9TNYrU66eru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cancer データ"
      ],
      "metadata": {
        "id": "gRs3b9V4wBaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの概要確認\n",
        "\n",
        "sklean ライブラリーに格納されているサンプルデータ（cancer data）を使い、\n",
        "**決定木**の説明を行う。\n",
        "以下のコードセルでは、データを読み込み、 info() を使い概要を表示する。"
      ],
      "metadata": {
        "id": "THzc4_hPdU3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
        "df['diagnosis'] = cancer.target\n",
        "\n",
        "#データの概要を表示\n",
        "df.info()"
      ],
      "metadata": {
        "id": "bPDzMK4uN0IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cancer データ とは、\n",
        "30項目の細胞に関連したデータ（サイズ、形状、など）と\n",
        "そこから判断された癌の診断結果（'diagnosis'）のデータである。\n",
        "\n",
        "全ての項目は数値型で、\n",
        "特に診断結果（'diagnosis'）は\n",
        "\n",
        "* 悪性の場合には 0\n",
        "* 良性の場合には 1\n",
        "\n",
        "が入力されており、\n",
        "このような項目を**2値**の項目と呼ぶ。\n",
        "\n",
        "このデータを学習させて、**癌の診断（良性か悪性かの分類）を行うAIを構築**する。"
      ],
      "metadata": {
        "id": "LdH53ARgIepY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず初めに、目的変数となる項目 diagnosis が2値となっていることを確認する。"
      ],
      "metadata": {
        "id": "vO3Wq2oqMfnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "FW_ER1W5-b3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "項目 diagnosis は数値型の項目ではあるが、値は 0 と 1 の2値となっていることが確かめられる。\n",
        "よって、\n",
        "diagnosis は、2 値の分類問題の目的変数として利用が可能である。"
      ],
      "metadata": {
        "id": "ZUq7hgo472nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ヒストグラムを作成して、各項目の分布を確認する。\n",
        "hue を使い目的変数の項目（diagnosis）で色分けしてみる。"
      ],
      "metadata": {
        "id": "F-qS51aHhHhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='mean radius', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "VNU4Aza-Dcie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "diagnosis は、0 が悪性、1 が良性であった。\n",
        "このグラフからは、mean radius がおよそ18をこえるとほぼ全てが悪性、\n",
        "逆に10を下回るとほぼ全てが良性になっていることが分かる。\n",
        "\n",
        "一方で、10から18の間では、良性も悪性もあり、この項目だけでは\n",
        "悪性か良性かを判断できないが、\n",
        "これ以外の検査項目も説明変数に用いることで\n",
        "癌の診断を行うAIを作る。"
      ],
      "metadata": {
        "id": "bG_bnzU9yk52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 決定木\n",
        "悪性か良性かといった分類問題に対する代表的な機械学習の手法として、\n",
        "**決定木**の使い方を説明する。"
      ],
      "metadata": {
        "id": "kflta2TyOaRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 変数\n",
        "\n",
        "目的変数と説明変数は以下のとおりである。\n",
        "\n",
        "* **目的変数：** 予測の対象となる項目。上のデータでは diagnosis である。\n",
        "* **説明変数：** 予測する元になる項目。上のデータでは30項目の数値型データがある。\n",
        "\n",
        "\n",
        "なお、決定木の場合には、**説明変数の標準化は不要である**。\n"
      ],
      "metadata": {
        "id": "XECHEz4EhU7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##決定木モデルを学習する"
      ],
      "metadata": {
        "id": "4I3xbCtTxWvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "説明変数と目的変数をそれぞれ変数 X と y にセットし、\n",
        "その後、\n",
        "train_test_split() を使い、全データを**学習用データ**と**検証データ**に分割をする。"
      ],
      "metadata": {
        "id": "Spn955w6t_Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 項目'diagnosis'は変数dfの最後にある項目なので、それを除くと説明変数のみとなる\n",
        "X = df.iloc[:,:-1]\n",
        "y = df[['diagnosis']]\n",
        "\n",
        "# データを学習用データと検証用データに分割\n",
        "# test_size は、0.2 程度が良いとされる\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "pyHf_wHjOknH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の作成には、DecisionTreeClassifier() を用いる。\n",
        "なお、max_depth は決定木のハイパーパラメータである。\n",
        "説明の都合、max_depth = 2 として決定木を作るが、\n",
        "後ほど、ハイパーパラメータチューニングを行う。"
      ],
      "metadata": {
        "id": "RkykhaigN0Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木に必要なライブラリー\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 決定木の準備\n",
        "model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "rhyQN6dmeEWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の内部では、以下の図に示すような\n",
        "予測がモデルが構築される。"
      ],
      "metadata": {
        "id": "4J3fhou1O_ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 決定木の可視化\n",
        "plt.figure(figsize=(16,6))\n",
        "plot_tree(model, filled=True, feature_names=cancer.feature_names, class_names=['0（悪性）','1（良性）'], fontsize=14)\n",
        "plt.title(\"Decision Tree of Cancer Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMmARcJNDi9R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木モデルでは、説明変数の値の大小で\n",
        "上の図のように枝分かれしながら予測が行われる。\n",
        "説明変数の値が不等式の条件を満たせば（True）左、\n",
        "満たさない（False）場合は右方向に枝を下方向にたどりながら、\n",
        "最後に到達した箱の class が予測結果である。\n",
        "\n",
        "なお、上の例では max_depth=2 と指定したので、\n",
        "二回枝分かれをするモデルになっている。\n",
        "また、枝分かれに用いられた項目は\n",
        "worst concave points\n",
        "と\n",
        "worst area\n",
        "の二つであった。\n",
        "他の説明変数の中から\n",
        "この二つが目的変数（この例では良性か悪性か）の判断に有効である、\n",
        "との結果になったことを意味している。\n",
        "\n",
        "例えば、ある細胞のデータが、\n",
        "\n",
        "* worst concave points = 0.2\n",
        "* worst area = 700\n",
        "\n",
        "であった場合、予測結果は class=1 (良性)と判定される。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0HAiK8PQP1IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定木の様子を、散布図を使って可視化すると以下のようになる。"
      ],
      "metadata": {
        "id": "PR9vnh4ZeDf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting with added lines\n",
        "sns.jointplot(x='worst concave points', y='worst area', data=df, hue='diagnosis')\n",
        "plt.axvline(x=0.142, color='red', linestyle='--')  # Add vertical line at x = 0.142\n",
        "plt.plot([-0.02, 0.142], [957.45, 957.45], color='red', linestyle='--') # Add line segment\n",
        "plt.plot([0.142,0.35], [729.55, 729.55], color='red', linestyle='--') # Add line segment\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uePNSsI7becI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='worst concave points', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "gZpKmrf2GIVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df, x='worst area', hue='diagnosis', kde=True)"
      ],
      "metadata": {
        "id": "abUwm9xtbUjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 評価用のデータを使い予測精度を確認する"
      ],
      "metadata": {
        "id": "XC28vVTzraqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "wGnlA5gerXf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "混同行列（confusion matrix）でも確認する。"
      ],
      "metadata": {
        "id": "eHhTt36wYUki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "metadata": {
        "id": "rSOYxiTfX4ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic データを使った例（決定木）"
      ],
      "metadata": {
        "id": "TKlOXVFpJj7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを読み込む\n",
        "data = sns.load_dataset(\"titanic\") #タイタニックのデータ\n",
        "data.info()\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "j_M6pfGUdT3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##データの説明\n",
        "\n",
        "列名 | 意味\n",
        "---  | ---\n",
        "survived\t| 生存フラグ（0=死亡、1=生存）\n",
        "pclass\t| チケットクラス（1stクラス、2ndクラス、3rdクラス）\n",
        "sex\t| 性別（male=男性、female＝女性）\n",
        "sge\t| 年齢\n",
        "sibsp\t| タイタニックに同乗している兄弟/配偶者の数\n",
        "parch\t| タイタニックに同乗している親/子供の数\n",
        "fare\t| 料金\n",
        "embarked\t| 出港地（タイタニックへ乗った港）(C=Cherbourg、Q=Queenstown、S=Southampton)\n",
        "class | 乗船クラス\n",
        "who |男性 or 女性\n",
        "adult_male | 成人男性であるかどうか\n",
        "deck | 乗船していたデッキ\n",
        "embark_town | 出港地\n",
        "alive | 生存したかどうか\n",
        "alone | 一人であったかどうか"
      ],
      "metadata": {
        "id": "t7UJupBadfY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 欠損値を埋める\n",
        "data['age'] = data['age'].fillna(data['age'].mean() )\n",
        "data['embarked'] = data['embarked'].fillna(data['embarked'].mode()[0] )\n",
        "data['embark_town'] = data['embark_town'].fillna(data['embark_town'].mode()[0] )\n",
        "# 結果を確認\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "_jzkQkrvd8kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "カテゴリ変数の項目に対しては One Hot Encoding を行い、\n",
        "数値型の変数に変換を行う。"
      ],
      "metadata": {
        "id": "PE7WK-g9ffeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# カテゴリ変数をOne Hot Encoding\n",
        "data_encoded = pd.get_dummies(data[['sex', 'embarked', 'class', 'who', 'adult_male', 'alone']], drop_first=True)\n",
        "\n",
        "# 説明変数と目的変数を設定\n",
        "X = pd.concat([data[['age', 'fare', 'sibsp', 'parch']], data_encoded], axis=1)\n",
        "y = data['survived']"
      ],
      "metadata": {
        "id": "p9WKguxbTHe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ハイパーパラメータの max_depth を 2 として決定木を作る。"
      ],
      "metadata": {
        "id": "KkpE3METg9Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 最適なモデルを作成\n",
        "model = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 検証用データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "um78RN1OSiSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(10,5))\n",
        "plot_tree(model, filled=True,  fontsize=14, feature_names=X.columns[:-1], class_names=['0(死亡)','1(生存)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KqOSpXd9b3pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一番上の who_man は、カテゴリ項目 who を One hot encoding した項目で、\n",
        "who の値が man であれば 1 、そうでないなら 0 になっている。\n",
        "\n",
        "who_man <= 0.5 という不等式なので、0 （すなわち man でない）ならば左側に、\n",
        "1 ならば右側に枝分かれする。\n",
        "\n",
        "例えば、\n",
        "* who = woman\n",
        "* class = Third\n",
        "の場合は「死亡」と予測されることになる。\n"
      ],
      "metadata": {
        "id": "ISLznoFbu63g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング\n",
        "\n",
        "決定木のハイパーパラメータは max_depth である。\n",
        "max_depth を 2から20の範囲で\n",
        "以下のようにグリッドサーチを行う。\n"
      ],
      "metadata": {
        "id": "MJCqr3iMhLj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 10, 20]\n",
        "    }\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV( DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "q1GBsffU5UGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "最適なパラメータは grid_search.best_estimator_ にセットされる。"
      ],
      "metadata": {
        "id": "bbuhqJ99iSPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "6R1Lgci9aK8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最適なモデルを作成\n",
        "model = grid_search.best_estimator_\n",
        "model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# テストデータで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "XKZ9OmOGadY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 決定木を可視化する\n",
        "plt.figure(figsize=(15,7))\n",
        "plot_tree(model, filled=True,  fontsize=13, feature_names=X.columns[:-1], class_names=['0(死亡)','1(生存)'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fo8ix57GjX22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "sKSxEjEQyAue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ランダムフォレスト\n",
        "分類問題に対する代表的な機械学習の手法として、\n",
        "**「ランダムフォレスト」**の使い方を説明する。\n",
        "\n",
        "ランダムフォレストは、決定木を複雑に組み合わせた構造を持ち、\n",
        "高い予測精度となるように工夫されてる。\n",
        "決定木と同様に、カテゴリ型の予測だけでなく\n",
        "数値型の予測も行える高精度な万能な予測手法である。\n",
        "ビジネスでも多く用いられている手法である。\n",
        "\n",
        "ただし、決定木のように予測の内部構造を可視化することができない。\n",
        "また、ランダムフォレストを利用するためには、\n",
        "複数のハイパーパラメータの調整が必要で、\n",
        "他の機械学習法と比べて多くの計算時間を必要とする。\n"
      ],
      "metadata": {
        "id": "-LjhwtSgB3va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ランダムフォレストモデルを学習する"
      ],
      "metadata": {
        "id": "N0DJ5GwBB3vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデル構築の手順は決定木と同様で、\n",
        "以下のように変数 model に RandomForestClassifier() をセットした後、\n",
        " fit で学習を行う。\n",
        "```\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(説明変数, 目的変数)\n",
        "```\n",
        "\n",
        "Titanic データを使いランダムフォレストモデルの予測精度を評価する。"
      ],
      "metadata": {
        "id": "ryOuMaiEB3vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ランダムフォレストの準備（初期設定）\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "l1bfdIMxB3vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 評価データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "UKXQlC4kB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 変数の重要度\n",
        "\n",
        "ランダムフォレストでは、説明変数の重要度を表示できる。\n",
        "値が大きいほど、予測精度に寄与する度合いが大きいことを意味している。\n",
        "逆に、\n",
        "重要度の小さな変数は、それを用いなくてもほとんど精度に影響がない変数である。\n",
        "また、重要度の値は全て正となり、回帰係数とは異なる意味合いの物である。"
      ],
      "metadata": {
        "id": "SoZUfZShB3vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.feature_importances_"
      ],
      "metadata": {
        "id": "kXoL1pMwB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量の重要度を可視化\n",
        "sns.barplot(x=model.feature_importances_, y=X.columns)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O8phEcnwB3vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータチューニング\n",
        "\n",
        "ランダムフォレストを利用するためには、\n",
        "いくつかのハイパーパラメータを適切に設定する必要がある。\n",
        "上の例ではデフォルト値が用いられているが、\n",
        "変更することでより精度を向上させることが可能である。\n",
        "\n",
        "調整することで精度の向上が期待できるパラメーターには以下のものがある。\n",
        "\n",
        "*  n_estimators（木の数）: 10 ～ 1000 程度\n",
        "*  max_depth（木の深さ） : 3 ～ 100 程度\n",
        "*  min_samples_split（分割の最小のサンプル数）: 2 ～ 100 程度"
      ],
      "metadata": {
        "id": "LnnPimVGB3vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ランダムフォレストに必要なライブラリー\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ハイパーパラメータの候補\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 50],\n",
        "    'max_depth': [3, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# グリッドサーチで最適なハイパーパラメータを探す\n",
        "grid_search = GridSearchCV( RandomForestClassifier(), param_grid=param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# 最適なハイパーパラメータを出力\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "# 最適なモデルを作成\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "# 学習\n",
        "model.fit(X_train, y_train.values.ravel())\n"
      ],
      "metadata": {
        "id": "d7LavvorB3vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 精度の評価\n",
        "\n",
        "評価用のデータセットを用いて精度の評価を行う。\n"
      ],
      "metadata": {
        "id": "Qgee4DKUB3vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 評価データで予測\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 精度を計算\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "m3mIlrVJB3vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "検証用データの場合で、混同行列を作成する。"
      ],
      "metadata": {
        "id": "9QnbWB2OB3vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_val, y_pred)"
      ],
      "metadata": {
        "id": "_-4BQGZAB3vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "D2u9eGlQai1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#【参考】詳しい説明が書かれたサイト\n",
        "\n",
        "各モジュールの詳しい使い方は以下のサイトに記載されている。\n",
        "\n",
        "https://scikit-learn.org/stable/api/sklearn.tree.html\n"
      ],
      "metadata": {
        "id": "JCJUulT9-jTY"
      }
    }
  ]
}